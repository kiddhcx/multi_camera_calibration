{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from Calibration.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class oneCamData:\n",
    "    def __init__(self, data_dir, cam, square_size, pattern_size, start_idx, num_frame, depth_only):\n",
    "        print('---------------------------------------------------------')\n",
    "        print('>>> Initilize camera %s' % cam)\n",
    "        self.data_dir = data_dir\n",
    "        self.cam = cam\n",
    "        self.square_size = square_size\n",
    "        self.pattern_size = pattern_size  # (col, row)\n",
    "        self.pattern_points = self.init_pattern_points()\n",
    "        self.cns_pattern = None\n",
    "        self.start_idx = start_idx\n",
    "        self.num_frame = num_frame\n",
    "\n",
    "        if 'kinect' in self.cam:\n",
    "            self.imgs_d = None\n",
    "            self.imgs_c = None\n",
    "            self.imgs_gray = None\n",
    "\n",
    "            self.intr_c = None\n",
    "            self.intr_d = None\n",
    "            self.intr = None\n",
    "            self.T_d2c = None\n",
    "\n",
    "            self.cns_c = None  # color corners, np.array [num_imgs, num_corners, 2]\n",
    "            self.cns_gray = None  # infrared norners, np.array [num_imgs, num_corners, 2]\n",
    "            self.cns_flag = None  # indicate if corners can be detected, np.array [num_imgs]\n",
    "        else:\n",
    "            self.imgs_gray = None\n",
    "            self.intr_c = None  # not use\n",
    "            self.intr_d = None  # not use\n",
    "            self.intr = None  # intrinsic parameters\n",
    "            self.cns_gray = None  # corners, np.array [num_imgs, num_corners, 2]\n",
    "            self.cns_flag = None  # indicate if corners can be detected, np.array [num_imgs]\n",
    "\n",
    "        self.load_images(depth_only=depth_only)\n",
    "        self.load_corners()\n",
    "        self.load_cam_params()\n",
    "\n",
    "    def init_pattern_points(self):\n",
    "        col, row = self.pattern_size\n",
    "        objp = np.zeros((col * row, 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:col, 0:row].T.reshape(-1, 2) * float(self.square_size)\n",
    "        return objp\n",
    "\n",
    "    def load_images(self, depth_only):\n",
    "        file_path = '%s/%s_calib_snap' % (self.data_dir, self.cam)\n",
    "        if 'kinect' in self.cam and depth_only:\n",
    "            # only depth image is loaded\n",
    "            imgs_d = []\n",
    "            for i in range(self.num_frame):\n",
    "                fname = '%s/depth%4i.png' % (file_path, i + self.start_idx)\n",
    "                img_d = cv2.imread(fname, -1).astype(np.float32)\n",
    "                imgs_d.append(img_d)\n",
    "            self.imgs_d = np.stack(imgs_d, axis=0)\n",
    "            print('[%s] only depth images are loaded.' % self.cam, 'shape ', self.imgs_d.shape)\n",
    "\n",
    "        elif 'kinect' in self.cam and not depth_only:\n",
    "            imgs_d, imgs_c, imgs_gray = [], [], []\n",
    "            for i in range(self.num_frame):\n",
    "                fname = '%s/depth%04i.png' % (file_path, i + self.start_idx)\n",
    "                # print(fname)\n",
    "                img_d = cv2.imread(fname, -1).astype(np.float32)\n",
    "                imgs_d.append(img_d)\n",
    "\n",
    "                fname = '%s/infrared%04i.png' % (file_path, i + self.start_idx)\n",
    "                # print(fname)\n",
    "                img_i = np.clip(cv2.imread(fname, -1).astype(np.float32) * 0.2, 0, 255).astype(np.uint8)\n",
    "                imgs_gray.append(img_i)\n",
    "\n",
    "                fname = '%s/color%04i.jpg' % (file_path, i + self.start_idx)\n",
    "                # print(fname)\n",
    "                img_c = cv2.imread(fname)\n",
    "                imgs_c.append(img_c)\n",
    "\n",
    "            self.imgs_d = np.stack(imgs_d, axis=0)\n",
    "            self.imgs_gray = np.stack(imgs_gray, axis=0)\n",
    "            self.imgs_c = np.stack(imgs_c, axis=0)\n",
    "            print('[%s] images are loaded. ' % self.cam,\n",
    "                  'shape ', self.imgs_c.shape, self.imgs_gray.shape, self.imgs_d.shape)\n",
    "\n",
    "        else:\n",
    "            # polar or event camera\n",
    "            imgs_gray = []\n",
    "            for i in range(self.num_frame):\n",
    "                if 'event' in self.cam:\n",
    "                    fname = '%s/fullpic%04i.jpg' % (file_path, i + self.start_idx)\n",
    "                else:\n",
    "                    fname = '%s/polar0_%04i.jpg' % (file_path, i + self.start_idx)\n",
    "                # print(fname)\n",
    "                img_g = cv2.imread(fname)\n",
    "                imgs_gray.append(img_g)\n",
    "            self.imgs_gray = np.stack(imgs_gray, axis=0)\n",
    "            print('[%s] images are loaded.' % self.cam, 'shape ', self.imgs_gray.shape)\n",
    "\n",
    "    def load_cam_params(self):\n",
    "        if 'kinect' in self.cam:\n",
    "            with open('%s/intrinsic_param.pkl' % self.data_dir, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.intr_c = data['%s_color' % self.cam]\n",
    "                self.intr_d = data['%s_depth' % self.cam]\n",
    "\n",
    "            with open('%s/kinect_extrinsic_param.pkl' % self.data_dir, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                r, t = data['%s_d2c' % self.cam]\n",
    "                self.T_d2c = Transform(r=r, t=t)\n",
    "            print('[%s] camera params are loaded.' % self.cam)\n",
    "\n",
    "        else:\n",
    "            with open('%s/intrinsic_param.pkl' % self.data_dir, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.intr = data['%s' % self.cam]\n",
    "            print('[%s] camera intrinsic params are loaded.' % self.cam)\n",
    "\n",
    "    def detect_corners(self):\n",
    "        col, row = self.pattern_size\n",
    "        criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 30, 0.001)\n",
    "        if 'kinect' in self.cam:\n",
    "            # kinect\n",
    "            obj_points, img_points_c, img_points_i, flags = [], [], [], []\n",
    "            for i in range(self.num_frame):\n",
    "                img_c = cv2.cvtColor(self.imgs_c[i], cv2.COLOR_BGR2GRAY)\n",
    "                img_i = self.imgs_gray[i]\n",
    "\n",
    "                ret_i, corners_i = cv2.findChessboardCorners(img_i, (col, row), None)\n",
    "                ret_c, corners_c = cv2.findChessboardCorners(img_c, (col, row), None)\n",
    "                obj_points.append(self.pattern_points)\n",
    "                if ret_i and ret_c:\n",
    "                    flags.append(True)\n",
    "                    corners2_i = cv2.cornerSubPix(img_i, corners_i, (5, 5), (-1, -1), criteria)\n",
    "                    img_points_i.append(np.squeeze(corners2_i))\n",
    "                    corners2_c = cv2.cornerSubPix(img_c, corners_c, (5, 5), (-1, -1), criteria)\n",
    "                    img_points_c.append(np.squeeze(corners2_c))\n",
    "\n",
    "                    cv2.drawChessboardCorners(img_c, (col, row), corners2_c, ret_c)\n",
    "                    cv2.imshow('img_c', cv2.resize(img_c, (int(img_c.shape[1]/2), int(img_c.shape[0]/2))))\n",
    "                    cv2.waitKey(50)\n",
    "\n",
    "                    cv2.drawChessboardCorners(img_i, (col, row), corners2_i, ret_i)\n",
    "                    cv2.imshow('img_i', img_i)\n",
    "                    cv2.waitKey(50)\n",
    "                else:\n",
    "                    flags.append(False)\n",
    "                    img_points_i.append(np.zeros_like(self.pattern_points[:, 0:2]))\n",
    "                    img_points_c.append(np.zeros_like(self.pattern_points[:, 0:2]))\n",
    "            cv2.destroyAllWindows()\n",
    "            obj_points = np.stack(obj_points, axis=0)\n",
    "            img_points_i = np.stack(img_points_i, axis=0)\n",
    "            img_points_c = np.stack(img_points_c, axis=0)\n",
    "            flags = np.asarray(flags)\n",
    "            print('[%s] finish detecting corners, [%i True, %i False]'\n",
    "                  % (self.cam, np.sum(flags==True), np.sum(flags==False)))\n",
    "\n",
    "            # save as .pkl\n",
    "            # file_path = '%s/%s_corners.pkl' % (self.data_dir, self.cam)\n",
    "            data = [obj_points, img_points_c, img_points_i, flags]\n",
    "            # with open(file_path, 'wb') as f:\n",
    "            #     pickle.dump(data, f)\n",
    "            #     print('saved as %s' % file_path)\n",
    "            return data\n",
    "\n",
    "        else:\n",
    "            obj_points, img_points, flags = [], [], []\n",
    "            for i in range(self.num_frame):\n",
    "                img = self.imgs_gray[i]\n",
    "                ret, corners = cv2.findChessboardCorners(img[:, :, 0], (col, row), None)\n",
    "                flags.append(ret)\n",
    "                obj_points.append(self.pattern_points)\n",
    "                if ret:\n",
    "                    corners2 = cv2.cornerSubPix(img[:, :, 0], corners, (5, 5), (-1, -1), criteria)\n",
    "                    img_points.append(np.squeeze(corners2))\n",
    "\n",
    "                    cv2.drawChessboardCorners(img, (col, row), corners2, ret)\n",
    "                    cv2.imshow('img', cv2.resize(img, (int(img.shape[1]/2), int(img.shape[0]/2))))\n",
    "                    cv2.waitKey(50)\n",
    "                else:\n",
    "                    img_points.append(np.zeros_like(self.pattern_points[:, 0:2]))\n",
    "            cv2.destroyAllWindows()\n",
    "            obj_points = np.stack(obj_points, axis=0)\n",
    "            img_points = np.stack(img_points, axis=0)\n",
    "            flags = np.asarray(flags)\n",
    "            print('[%s] finish detecting corners, [%i True, %i False]'\n",
    "                  % (self.cam, np.sum(flags==True), np.sum(flags==False)))\n",
    "\n",
    "            # save as .pkl\n",
    "            # file_path = '%s/%s_corners.pkl' % (self.data_dir, self.cam)\n",
    "            data = [obj_points, img_points, flags]\n",
    "            # with open(file_path, 'wb') as f:\n",
    "            #     pickle.dump(data, f)\n",
    "            #     print('saved as %s' % file_path)\n",
    "            return data\n",
    "\n",
    "    def load_corners(self):\n",
    "        if 'kinect' in self.cam:\n",
    "            # detect corners\n",
    "            self.cns_pattern, self.cns_c, self.cns_gray, self.cns_flag = self.detect_corners()\n",
    "            print('shape ', self.cns_pattern.shape, self.cns_c.shape, self.cns_gray.shape, self.cns_flag.shape)\n",
    "\n",
    "        else:\n",
    "            # detect corners\n",
    "            self.cns_pattern, self.cns_gray, self.cns_flag = self.detect_corners()\n",
    "            print('shape ', self.cns_pattern.shape, self.cns_gray.shape, self.cns_flag.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class onePairCamsData:\n",
    "    def __init__(self, data_dir, cam1, cam2, square_size, pattern_size, start_idx, num_frame, depth_only):\n",
    "        self.cam1 = cam1\n",
    "        self.cam2 = cam2\n",
    "        self.data_dir = data_dir\n",
    "        self.pattern_size = pattern_size\n",
    "        self.cam_pair_data = self.align_corners_pair(square_size, pattern_size, start_idx, num_frame, depth_only)\n",
    "\n",
    "    def align_corners_pair(self, square_size, pattern_size, start_idx, num_frame, depth_only):\n",
    "        cam1_data = oneCamData(self.data_dir, self.cam1, square_size, pattern_size, start_idx, num_frame, depth_only)\n",
    "        cam2_data = oneCamData(self.data_dir, self.cam2, square_size, pattern_size, start_idx, num_frame, depth_only)\n",
    "\n",
    "        flags = cam1_data.cns_flag & cam2_data.cns_flag\n",
    "        cns_pattern = cam1_data.cns_pattern[flags]\n",
    "\n",
    "        cns_gray1 = cam1_data.cns_gray[flags]\n",
    "        imgs_gray1 = cam1_data.imgs_gray[flags]\n",
    "        if 'kinect' in self.cam1:\n",
    "            cns_c1 = cam1_data.cns_c[flags]\n",
    "            imgs_c1 = cam1_data.imgs_c[flags]\n",
    "            imgs_d1 = cam1_data.imgs_d[flags]\n",
    "        else:\n",
    "            imgs_c1, imgs_d1, cns_c1 = None, None, None\n",
    "\n",
    "        cns_gray2 = cam2_data.cns_gray[flags]\n",
    "        imgs_gray2 = cam2_data.imgs_gray[flags]\n",
    "        if 'kinect' in self.cam2:\n",
    "            cns_c2 = cam2_data.cns_c[flags]\n",
    "            imgs_c2 = cam2_data.imgs_c[flags]\n",
    "            imgs_d2 = cam2_data.imgs_d[flags]\n",
    "        else:\n",
    "            cns_c2, imgs_c2, imgs_d2 = None, None, None\n",
    "\n",
    "        cns_gray1, cns_gray2, cns_c1, cns_c2 = self.flip_corners(cns_gray1, cns_gray2, cns_c1, cns_c2)\n",
    "        print('---------------------------------------------------------')\n",
    "        print('aligned [%s] and [%s], [%i True, %i False]' %\n",
    "              (self.cam1, self.cam2, np.sum(flags==True), np.sum(flags==False)))\n",
    "\n",
    "        data_cam_pairs = {\n",
    "            'flags': flags,\n",
    "            'pattern_size': cam1_data.pattern_size,\n",
    "            'valid_num_frame': np.sum(flags).astype(np.int32),\n",
    "            'num_frame': cam1_data.num_frame,\n",
    "            'cns_pattern': cns_pattern,\n",
    "            'cns_gray1': cns_gray1,\n",
    "            'cns_c1': cns_c1,\n",
    "            'imgs_gray1': imgs_gray1,\n",
    "            'imgs_c1': imgs_c1,\n",
    "            'imgs_d1': imgs_d1,\n",
    "            'intr_params_1': cam1_data.intr,\n",
    "            'intr_params_c1': cam1_data.intr_c,\n",
    "            'intr_params_d1': cam1_data.intr_d,\n",
    "            'cns_gray2': cns_gray2,\n",
    "            'cns_c2': cns_c2,\n",
    "            'imgs_gray2': imgs_gray2,\n",
    "            'imgs_c2': imgs_c2,\n",
    "            'imgs_d2': imgs_d2,\n",
    "            'intr_params_2': cam2_data.intr,\n",
    "            'intr_params_c2': cam2_data.intr_c,\n",
    "            'intr_params_d2': cam2_data.intr_d}\n",
    "        return data_cam_pairs\n",
    "\n",
    "    def flip_corners(self, cns_gray1, cns_gray2, cns_c1, cns_c2):\n",
    "        _cns_gray1, _cns_gray2 = cns_gray1.copy(), cns_gray2.copy()\n",
    "        if cns_c1 is not None:\n",
    "            _cns_c1 = cns_c1.copy()\n",
    "        else:\n",
    "            _cns_c1 = cns_c1\n",
    "        if cns_c2 is not None:\n",
    "            _cns_c2 = cns_c2.copy()\n",
    "        else:\n",
    "            _cns_c2 = cns_c2\n",
    "\n",
    "        num_imgs = _cns_gray1.shape[0]\n",
    "        for i in range(num_imgs):\n",
    "            cn_gray1 = cns_gray1[i]\n",
    "            cn_gray2 = cns_gray2[i]\n",
    "\n",
    "            vec_1 = (cn_gray1[0, :] - cn_gray1[-1, :]) / np.linalg.norm(cn_gray1[0, :] - cn_gray1[-1, :])\n",
    "            vec_2 = (cn_gray2[0, :] - cn_gray2[-1, :]) / np.linalg.norm(cn_gray2[0, :] - cn_gray2[-1, :])\n",
    "            if np.dot(vec_1, vec_2) < 0:\n",
    "                _cns_gray1[i] = cn_gray1[::-1]\n",
    "                _cns_gray2[i] = cn_gray2[::-1]\n",
    "                if cns_c1 is not None:\n",
    "                    cn_c1 = cns_c1[i]\n",
    "                    _cns_c1[i] = cn_c1[::-1]\n",
    "                if cns_c2 is not None:\n",
    "                    cn_c2 = cns_c2[i]\n",
    "                    _cns_c2[i] = cn_c2[::-1]\n",
    "\n",
    "        return _cns_gray1, _cns_gray2, _cns_c1, _cns_c2\n",
    "\n",
    "    def observe_corners(self):\n",
    "        data = self.cam_pair_data\n",
    "        for j in range(data.get('valid_num_frame')):\n",
    "            if 'kinect' in self.cam1:\n",
    "                pass\n",
    "            else:\n",
    "                img_gray1 = data['imgs_gray1'][j]\n",
    "                corners_gray1 = data['cns_gray1'][j]\n",
    "                cv2.drawChessboardCorners(img_gray1, self.pattern_size, corners_gray1, True)\n",
    "                cv2.imshow('img_gray1',\n",
    "                           cv2.resize(img_gray1, (int(img_gray1.shape[1]/2), int(img_gray1.shape[0]/2))))\n",
    "                cv2.waitKey()\n",
    "\n",
    "            if 'kinect' in self.cam2:\n",
    "                pass\n",
    "            else:\n",
    "                img_gray2 = data['imgs_gray2'][j]\n",
    "                corners_gray2 = data['cns_gray2'][j]\n",
    "                cv2.drawChessboardCorners(img_gray2, self.pattern_size, corners_gray2, True)\n",
    "                cv2.imshow('img_gray2',\n",
    "                           cv2.resize(img_gray2, (int(img_gray2.shape[1]/2), int(img_gray2.shape[0]/2))))\n",
    "                cv2.waitKey()\n",
    "\n",
    "            if data['imgs_c1'] is not None:\n",
    "                img_c1 = data['imgs_c1'][j]\n",
    "                corners_c1 = data['cns_c1'][j]\n",
    "                cv2.drawChessboardCorners(img_c1, self.pattern_size, corners_c1, True)\n",
    "                cv2.imshow('img_color1', cv2.resize(img_c1, (int(img_c1.shape[1]/2), int(img_c1.shape[0]/2))))\n",
    "                cv2.waitKey()\n",
    "\n",
    "            if data['imgs_c2'] is not None:\n",
    "                img_c2 = data['imgs_c2'][j]\n",
    "                corners_c2 = data['cns_c2'][j]\n",
    "                cv2.drawChessboardCorners(img_c2, self.pattern_size, corners_c2, True)\n",
    "                cv2.imshow('img_color2', cv2.resize(img_c2, (int(img_c2.shape[1]/2), int(img_c2.shape[0]/2))))\n",
    "                cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def estimate_transform(data_cam_pairs, cam1, cam2):\n",
    "    print('---------------------------------------------------------')\n",
    "    if 'kinect' not in cam1:\n",
    "        ls_T_cam1w = get_img2w_transform(data_cam_pairs['cns_gray1'], data_cam_pairs['cns_pattern'],\n",
    "                                         data_cam_pairs['intr_params_1'], cam1)\n",
    "    else:\n",
    "        ls_T_cam1w = get_depth2w_transform(data_cam_pairs['imgs_d1'], data_cam_pairs['cns_gray1'],\n",
    "                                           data_cam_pairs['cns_pattern'], data_cam_pairs['intr_params_d1'],\n",
    "                                           data_cam_pairs['pattern_size'], cam1)\n",
    "\n",
    "    if 'kinect' not in cam2:\n",
    "        ls_T_cam2w = get_img2w_transform(data_cam_pairs['cns_gray2'], data_cam_pairs['cns_pattern'],\n",
    "                                         data_cam_pairs['intr_params_2'], cam2)\n",
    "    else:\n",
    "        ls_T_cam2w = get_depth2w_transform(data_cam_pairs['imgs_d2'], data_cam_pairs['cns_gray2'],\n",
    "                                           data_cam_pairs['cns_pattern'], data_cam_pairs['intr_params_d2'],\n",
    "                                           data_cam_pairs['pattern_size'], cam2)\n",
    "\n",
    "    # for i in range(data_cam_pairs['valid_num_frame']):\n",
    "    #     T_cam1w = ls_T_cam1w[i]\n",
    "    #     cn_pattern = data_cam_pairs['cns_pattern'][i]\n",
    "    #     pts_cam1 = T_cam1w.transform(cn_pattern)\n",
    "    #     if 'kinect' in cam1:\n",
    "    #         uv_cam1 = projection(pts_cam1, data_cam_pairs['intr_params_d1'], False)\n",
    "    #     else:\n",
    "    #         uv_cam1 = projection(pts_cam1, data_cam_pairs['intr_params_1'], False)\n",
    "    #     error = np.mean(np.sqrt(np.sum((data_cam_pairs.get('cns_gray1')[i] - uv_cam1) ** 2, axis=1)))\n",
    "    #     print('error:', error)\n",
    "    #\n",
    "    # print('---------------------------------------------------------')\n",
    "    # for i in range(data_cam_pairs['valid_num_frame']):\n",
    "    #     T_cam2w = ls_T_cam2w[i]\n",
    "    #     cn_pattern = data_cam_pairs['cns_pattern'][i]\n",
    "    #     pts_cam2 = T_cam2w.transform(cn_pattern)\n",
    "    #     if 'kinect' in cam2:\n",
    "    #         uv_cam2 = projection(pts_cam2, data_cam_pairs['intr_params_d2'], False)\n",
    "    #     else:\n",
    "    #         uv_cam2 = projection(pts_cam2, data_cam_pairs['intr_params_2'], False)\n",
    "    #     error = np.mean(np.sqrt(np.sum((data_cam_pairs.get('cns_gray2')[i] - uv_cam2) ** 2, axis=1)))\n",
    "    #     print('error:', error)\n",
    "\n",
    "\n",
    "    # get transform\n",
    "    ls_T_cam1cam2 = []  # transform from cam2 to cam1\n",
    "    for i in range(data_cam_pairs['valid_num_frame']):\n",
    "        # print('-------------------------------------------------------')\n",
    "        T_cam1w = ls_T_cam1w[i]\n",
    "        # print(T_cam1w.r, '\\n', T_cam1w.t, '\\n')\n",
    "        T_cam2w = ls_T_cam2w[i]\n",
    "        # print(T_cam2w.r, '\\n', T_cam2w.t, '\\n')\n",
    "        _T_cam1cam2 = T_cam1w * T_cam2w.inv()\n",
    "        # print(_T_cam1cam2.r, '\\n', _T_cam1cam2.t, '\\n')\n",
    "        ls_T_cam1cam2.append(_T_cam1cam2)\n",
    "\n",
    "    # clustering\n",
    "    T_cam1cam2 = cluster_pose(ls_T_cam1cam2)\n",
    "    print(T_cam1cam2.r, '\\n', T_cam1cam2.t, '\\n')\n",
    "\n",
    "    # check errors\n",
    "    for i in range(data_cam_pairs['valid_num_frame']):\n",
    "        T_cam2w = ls_T_cam2w[i]\n",
    "        cn_pattern = data_cam_pairs['cns_pattern'][i]\n",
    "        pts_cam2 = T_cam2w.transform(cn_pattern)\n",
    "        pts_cam1 = T_cam1cam2.transform(pts_cam2)\n",
    "\n",
    "        if 'kinect' in cam1:\n",
    "            uv_cam1 = projection(pts_cam1, data_cam_pairs['intr_params_d1'], False)[:, 0:2]\n",
    "        else:\n",
    "            uv_cam1 = projection(pts_cam1, data_cam_pairs['intr_params_1'], False)[:, 0:2]\n",
    "        error = np.mean(np.sqrt(np.sum((data_cam_pairs.get('cns_gray1')[i] - uv_cam1) ** 2, axis=1)))\n",
    "        print('error:', error)\n",
    "\n",
    "    return T_cam1cam2\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# assert (cam1, cam2) in [('azure_kinect_2', 'kinect_v2_2'), ('azure_kinect_2', 'azure_kinect_0'),\n",
    "#                         ('polar', 'azure_kinect_0'), ('event_camera', 'azure_kinect_0'),\n",
    "#                         ('azure_kinect_1', 'azure_kinect_0'), ('azure_kinect_1', 'kinect_v2_1')]\n",
    "\n",
    "data_dir = 'D:/UoA_Research/data_11'\n",
    "# cam1 = 'event_camera'\n",
    "# cam2 = 'azure_kinect_0'\n",
    "# start_idx = 60\n",
    "square_size = 60.\n",
    "pattern_size = (8, 11)\n",
    "num_frame = 20\n",
    "depth_only = False\n",
    "\n",
    "# data = onePairCamsData(data_dir, cam1, cam2, square_size, pattern_size, start_idx, num_frame, depth_only)\n",
    "# data.observe_corners()\n",
    "# T_cam2cam1 = estimate_transform(data.cam_pair_data, cam1, cam2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_2\n",
      "[azure_kinect_2] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_2] finish detecting corners, [15 True, 5 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_2] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera kinect_v2_2\n",
      "[kinect_v2_2] images are loaded.  shape  (20, 1920, 1080, 3) (20, 512, 424) (20, 512, 424)\n",
      "[kinect_v2_2] finish detecting corners, [16 True, 4 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[kinect_v2_2] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [azure_kinect_2] and [kinect_v2_2], [11 True, 9 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1960.23753113 -579.31185515 1098.46230951]\n",
      "[0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.37361034  0.18518875 -0.90891168]\n",
      " [-0.17581992  0.97624312  0.12663618]\n",
      " [ 0.91077037  0.11249219  0.39729439]] \n",
      " [1960.23753113 -579.31185515 1098.46230951] \n",
      "\n",
      "error: 1.110127323566938\n",
      "error: 0.5847504599578423\n",
      "error: 0.5664995160454199\n",
      "error: 0.6413247562848017\n",
      "error: 0.6181068291562767\n",
      "error: 0.4921849963517225\n",
      "error: 0.590919480746395\n",
      "error: 0.810172255018466\n",
      "error: 0.8075254264985374\n",
      "error: 0.77789842208282\n",
      "error: 0.7686195682549145\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_0\n",
      "[azure_kinect_0] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_0] finish detecting corners, [20 True, 0 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_0] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_2\n",
      "[azure_kinect_2] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_2] finish detecting corners, [19 True, 1 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_2] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [azure_kinect_0] and [azure_kinect_2], [19 True, 1 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1640.69515123   12.86900027  960.24096852]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.57913545  0.04026335 -0.81423645]\n",
      " [-0.14330689  0.98825489 -0.05306032]\n",
      " [ 0.80253677  0.14741481  0.57810346]] \n",
      " [1640.69515123   12.86900027  960.24096852] \n",
      "\n",
      "error: 0.5767048166834855\n",
      "error: 0.6112796670974919\n",
      "error: 0.7193876758202241\n",
      "error: 0.6621062141601736\n",
      "error: 0.7165999587938002\n",
      "error: 0.6814117185159767\n",
      "error: 0.5835824714615692\n",
      "error: 0.7930410226853714\n",
      "error: 1.0549190632867365\n",
      "error: 0.8764037068060323\n",
      "error: 0.7503555782112378\n",
      "error: 1.3420695668882239\n",
      "error: 1.3949708327861525\n",
      "error: 1.1892515648007504\n",
      "error: 1.0415217982976317\n",
      "error: 0.6811265744047372\n",
      "error: 0.7114371087685654\n",
      "error: 0.7201380964014684\n",
      "error: 0.7885968731844016\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera polar\n",
      "[polar] images are loaded. shape  (20, 1024, 1224, 3)\n",
      "[polar] finish detecting corners, [20 True, 0 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20,)\n",
      "[polar] camera intrinsic params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_0\n",
      "[azure_kinect_0] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_0] finish detecting corners, [20 True, 0 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_0] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [polar] and [azure_kinect_0], [20 True, 0 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[-756.57847408  161.88774724 2635.04964159]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.89516486 -0.09109566  0.43632723]\n",
      " [ 0.07682225  0.99577578  0.05028858]\n",
      " [-0.43906516 -0.01149693  0.89838166]] \n",
      " [-756.57847408  161.88774724 2635.04964159] \n",
      "\n",
      "error: 0.7721824451659342\n",
      "error: 0.843553176641186\n",
      "error: 0.6295100992950798\n",
      "error: 0.4066320716340105\n",
      "error: 0.670012103664663\n",
      "error: 0.5636342735850218\n",
      "error: 0.5985910400576162\n",
      "error: 0.5955234976525098\n",
      "error: 0.6184697236881195\n",
      "error: 0.6363318609110815\n",
      "error: 1.9552437151270325\n",
      "error: 2.4092357857173297\n",
      "error: 1.9689932051930732\n",
      "error: 1.9590949087150862\n",
      "error: 2.4754473929015095\n",
      "error: 1.062973372948758\n",
      "error: 1.7695478832847522\n",
      "error: 2.8027185687562364\n",
      "error: 2.516670830411677\n",
      "error: 1.9790556268764539\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera event_camera\n",
      "[event_camera] images are loaded. shape  (20, 1280, 800, 3)\n",
      "[event_camera] finish detecting corners, [20 True, 0 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20,)\n",
      "[event_camera] camera intrinsic params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_0\n",
      "[azure_kinect_0] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_0] finish detecting corners, [20 True, 0 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_0] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [event_camera] and [azure_kinect_0], [20 True, 0 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 642.33468311  -19.79374815 1446.38060027]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.95507016  0.08849277 -0.28286043]\n",
      " [-0.04418231  0.9862311   0.15936169]\n",
      " [ 0.29306811 -0.13970417  0.9458297 ]] \n",
      " [ 642.33468311  -19.79374815 1446.38060027] \n",
      "\n",
      "error: 2.085284156372647\n",
      "error: 1.816896766861697\n",
      "error: 1.7592179176253255\n",
      "error: 1.6699982378192109\n",
      "error: 1.163309549145196\n",
      "error: 0.9025459188200265\n",
      "error: 1.9472175083176269\n",
      "error: 1.3213092655647705\n",
      "error: 1.757209815484667\n",
      "error: 1.4139320106941697\n",
      "error: 3.0567568736242303\n",
      "error: 3.7715768577939484\n",
      "error: 3.4791336632452667\n",
      "error: 2.793666098243852\n",
      "error: 3.080488104194807\n",
      "error: 5.571003817629033\n",
      "error: 3.823956865603957\n",
      "error: 3.214616579781736\n",
      "error: 2.7485910010395305\n",
      "error: 4.454810121209834\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_0\n",
      "[azure_kinect_0] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_0] finish detecting corners, [18 True, 2 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_0] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_1\n",
      "[azure_kinect_1] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_1] finish detecting corners, [17 True, 3 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_1] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [azure_kinect_0] and [azure_kinect_1], [15 True, 5 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[-1747.72631593    42.87419725   933.11764652]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.66169192 -0.02274623  0.74943073]\n",
      " [ 0.19528112  0.97027054 -0.14296978]\n",
      " [-0.72389853  0.24095162  0.64646209]] \n",
      " [-1747.72631593    42.87419725   933.11764652] \n",
      "\n",
      "error: 1.0376241328562947\n",
      "error: 1.0280595517406268\n",
      "error: 1.1681841461779188\n",
      "error: 1.0804568524389582\n",
      "error: 1.322697402381928\n",
      "error: 1.785839226537478\n",
      "error: 1.5948030341801434\n",
      "error: 1.4204624479645747\n",
      "error: 1.4639827399800203\n",
      "error: 1.8135783569220236\n",
      "error: 1.5888386201519602\n",
      "error: 0.8855482168629862\n",
      "error: 0.9901486429232181\n",
      "error: 1.1788784110066464\n",
      "error: 1.1352451655181484\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera azure_kinect_1\n",
      "[azure_kinect_1] images are loaded.  shape  (20, 1536, 2048, 3) (20, 576, 640) (20, 576, 640)\n",
      "[azure_kinect_1] finish detecting corners, [16 True, 4 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[azure_kinect_1] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      ">>> Initilize camera kinect_v2_1\n",
      "[kinect_v2_1] images are loaded.  shape  (20, 1920, 1080, 3) (20, 512, 424) (20, 512, 424)\n",
      "[kinect_v2_1] finish detecting corners, [19 True, 1 False]\n",
      "shape  (20, 88, 3) (20, 88, 2) (20, 88, 2) (20,)\n",
      "[kinect_v2_1] camera params are loaded.\n",
      "---------------------------------------------------------\n",
      "aligned [azure_kinect_1] and [kinect_v2_1], [16 True, 4 False]\n",
      "---------------------------------------------------------\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[-1723.2720887   -411.90040134  1212.71975883]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[ 0.44199574  0.02102015  0.89677083]\n",
      " [-0.14921203  0.98752016  0.05039556]\n",
      " [-0.88451995 -0.15608362  0.43961616]] \n",
      " [-1723.2720887   -411.90040134  1212.71975883] \n",
      "\n",
      "error: 0.6636007823810558\n",
      "error: 0.7267760225961828\n",
      "error: 0.7095193613187244\n",
      "error: 0.6662478154585316\n",
      "error: 1.1109120600955784\n",
      "error: 0.4819198342449474\n",
      "error: 0.6124385939153809\n",
      "error: 0.6669458614352515\n",
      "error: 0.8061041576613096\n",
      "error: 1.1176802026172359\n",
      "error: 1.3369743988070524\n",
      "error: 1.130580251589193\n",
      "error: 1.0556562996774679\n",
      "error: 1.19476577600746\n",
      "error: 1.2096372476082444\n",
      "error: 1.1735542129315137\n"
     ]
    }
   ],
   "source": [
    "extr_param = {}\n",
    "# from cam1 to cam2\n",
    "cam_pairs = [('azure_kinect_2', 'kinect_v2_2', 0),\n",
    "             ('azure_kinect_0', 'azure_kinect_2', 20),\n",
    "             ('polar', 'azure_kinect_0', 40),\n",
    "             ('event_camera', 'azure_kinect_0', 60),\n",
    "             ('azure_kinect_0', 'azure_kinect_1', 80),\n",
    "             ('azure_kinect_1', 'kinect_v2_1', 100)]\n",
    "\n",
    "for (cam1, cam2, start_idx) in cam_pairs:\n",
    "    data = onePairCamsData(data_dir, cam1, cam2, square_size, pattern_size, start_idx, num_frame, depth_only)\n",
    "    T_cam1cam2 = estimate_transform(data.cam_pair_data, cam1, cam2)\n",
    "    extr_param['%s-%s' % (cam1, cam2)] = (T_cam1cam2.r, T_cam1cam2.t)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure_kinect_2-kinect_v2_2 (array([[ 0.37361034,  0.18518875, -0.90891168],\n",
      "       [-0.17581992,  0.97624312,  0.12663618],\n",
      "       [ 0.91077037,  0.11249219,  0.39729439]]), array([1960.23753113, -579.31185515, 1098.46230951]))\n",
      "azure_kinect_0-azure_kinect_2 (array([[ 0.57913545,  0.04026335, -0.81423645],\n",
      "       [-0.14330689,  0.98825489, -0.05306032],\n",
      "       [ 0.80253677,  0.14741481,  0.57810346]]), array([1640.69515123,   12.86900027,  960.24096852]))\n",
      "polar-azure_kinect_0 (array([[ 0.89516486, -0.09109566,  0.43632723],\n",
      "       [ 0.07682225,  0.99577578,  0.05028858],\n",
      "       [-0.43906516, -0.01149693,  0.89838166]]), array([-756.57847408,  161.88774724, 2635.04964159]))\n",
      "event_camera-azure_kinect_0 (array([[ 0.95507016,  0.08849277, -0.28286043],\n",
      "       [-0.04418231,  0.9862311 ,  0.15936169],\n",
      "       [ 0.29306811, -0.13970417,  0.9458297 ]]), array([ 642.33468311,  -19.79374815, 1446.38060027]))\n",
      "azure_kinect_0-azure_kinect_1 (array([[ 0.66169192, -0.02274623,  0.74943073],\n",
      "       [ 0.19528112,  0.97027054, -0.14296978],\n",
      "       [-0.72389853,  0.24095162,  0.64646209]]), array([-1747.72631593,    42.87419725,   933.11764652]))\n",
      "azure_kinect_1-kinect_v2_1 (array([[ 0.44199574,  0.02102015,  0.89677083],\n",
      "       [-0.14921203,  0.98752016,  0.05039556],\n",
      "       [-0.88451995, -0.15608362,  0.43961616]]), array([-1723.2720887 ,  -411.90040134,  1212.71975883]))\n"
     ]
    }
   ],
   "source": [
    "for k, v in extr_param.items():\n",
    "    print(k, v)\n",
    "with open('%s/extrinsic_param.pkl' % data_dir, 'wb') as f:\n",
    "    pickle.dump(extr_param, f)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}