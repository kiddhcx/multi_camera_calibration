{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import pickle\n",
    "class camera_Data:\n",
    "    def __init__(self, name, cam_R, cam_T, flag):\n",
    "        self.name = name\n",
    "        self.R = cam_R\n",
    "        self.T = cam_T\n",
    "        self.flag = flag\n",
    "\n",
    "        \n",
    "def cluster_pose(cam_R, cam_T):\n",
    "    \"\"\"\n",
    "    :type ls_T: list[Transform]\n",
    "    \"\"\"\n",
    "    # cluster t\n",
    "    print(len(cam_T))\n",
    "    meanshift_t = sklearn.cluster.MeanShift(bandwidth=1000, bin_seeding=True)\n",
    "    meanshift_t.fit(cam_T)\n",
    "    print(meanshift_t.labels_)\n",
    "    #assert np.count_nonzero(meanshift_t.labels_ == 0) > (0.7 * len(cam_T))\n",
    "    t = meanshift_t.cluster_centers_[0]\n",
    "    print(t)\n",
    "\n",
    "    # cluster R\n",
    "    _Rs = np.array(cam_R)[meanshift_t.labels_ == 0]\n",
    "    _Rs = _Rs.reshape((-1, 9))\n",
    "    meanshift_R = sklearn.cluster.MeanShift(bandwidth=0.1)\n",
    "    meanshift_R.fit(_Rs)\n",
    "    print(meanshift_R.labels_)\n",
    "    _tmp = meanshift_t.labels_ == 0\n",
    "    assert isinstance(_tmp, np.ndarray)\n",
    "    assert np.count_nonzero(_tmp) > (0.7 * len(_Rs))\n",
    "    R = meanshift_R.cluster_centers_[0].reshape((3, 3))\n",
    "\n",
    "    # normalize\n",
    "    R = cv2.Rodrigues(cv2.Rodrigues(R)[0])[0]\n",
    "    return R, t\n",
    "\n",
    "def RT_calculate(cam1, cam2):\n",
    "    f = cam1.flag & cam2.flag\n",
    "    r1 = cam1.R[f]\n",
    "    t1 = cam1.T[f]\n",
    "    r2 = cam2.R[f]\n",
    "    t2 = cam2.T[f]\n",
    "    R = []\n",
    "    T = []\n",
    "    for i in range(r1.shape[0]):\n",
    "        r12 = np.dot(cv2.Rodrigues(r1[i])[0], cv2.Rodrigues(r2[i])[0].T)\n",
    "        t12 = t1[i] - np.dot(r12, t2[i])\n",
    "        R.append(r12)\n",
    "        T.append(t12)\n",
    "    R = np.squeeze(np.asarray(R))\n",
    "    T = np.squeeze(np.asarray(T))\n",
    "    \n",
    "    return cluster_pose(R, T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = r\"C:\\Users\\lovettxh\\Documents\\GitHub\\multi_camera_calibration\\calibration\\1024\"\n",
    "cam_list = ['kinect_v2_1', 'azure_kinect_1','azure_kinect_0',  'azure_kinect_2', 'kinect_v2_2']\n",
    "start_idx = [0, 0, 0, 0, 0]\n",
    "n_list = [124, 124, 124, 124, 124]\n",
    "col = 8\n",
    "row = 11\n",
    "square_size = 60.\n",
    "objp = np.zeros((col*row, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:col, 0:row].T.reshape(-1, 2) * square_size\n",
    "h = 0\n",
    "w = 0\n",
    "corner_m = []\n",
    "obj_m = []\n",
    "cams = {}\n",
    "for idx, cam in enumerate(cam_list):\n",
    "    obj_points = []\n",
    "    img_points = []\n",
    "    cam_R, cam_T, flag = [], [], []\n",
    "    cam_dir = \"%s/%s_calib_snap\" % (dir, cam)\n",
    "    for i in range(n_list[idx]):\n",
    "        filename = '%s/color%04i.jpg' % (cam_dir, i + start_idx[idx])\n",
    "        print(i)\n",
    "        img = cv2.imread(filename)\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (col, row), None)\n",
    "        flag.append(ret)\n",
    "        if ret:\n",
    "            print(filename)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (5, 5), (-1, -1), None)\n",
    "            obj_points.append(objp)\n",
    "            img_points.append(np.squeeze(corners2))\n",
    "        else:\n",
    "            obj_points.append(objp)\n",
    "            img_points.append(np.zeros((col*row, 2)))    \n",
    "    \n",
    "    obj_points= np.array(obj_points).astype('float32')\n",
    "    img_points= np.array(img_points).astype('float32')\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points[flag], img_points[flag], (w, h), None, None, flags=cv2.CALIB_RATIONAL_MODEL)\n",
    "    for i in range(n_list[idx]):\n",
    "        if flag[i]:\n",
    "            retval, rvec, tvec = cv2.solvePnP(objectPoints=obj_points[i], imagePoints=img_points[i], cameraMatrix=mtx, distCoeffs=dist)\n",
    "            cam_R.append(rvec)\n",
    "            cam_T.append(tvec)\n",
    "        else:\n",
    "            cam_R.append(np.zeros((3,1)))\n",
    "            cam_T.append(np.zeros((3,1)))\n",
    "    cams[cam] = camera_Data(cam, np.asarray(cam_R), np.asarray(cam_T), np.asarray(flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1755.05411089 -433.15100508 1156.9553154 ]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "42\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[1522.4574341   114.79700697  976.86899334]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "39\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[-1668.51543707   147.87110352   802.06265815]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "18\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[-1937.00554847  -244.77167949  1052.98422726]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "{'azure_kinect_2-kinect_v2_2_R': array([[ 0.47807969,  0.18101   , -0.85946215],\n",
      "       [-0.1261027 ,  0.9825414 ,  0.13678633],\n",
      "       [ 0.86921684,  0.04298573,  0.49255894]]), 'azure_kinect_2-kinect_v2_2_T': array([1755.05411089, -433.15100508, 1156.9553154 ]), 'azure_kinect_0-azure_kinect_2_R': array([[ 0.58549045, -0.03247262, -0.81002868],\n",
      "       [-0.03981115,  0.99684015, -0.06873715],\n",
      "       [ 0.80970118,  0.07249312,  0.58234761]]), 'azure_kinect_0-azure_kinect_2_T': array([1522.4574341 ,  114.79700697,  976.86899334]), 'azure_kinect_0-azure_kinect_1_R': array([[ 0.71277084,  0.05202333,  0.69946501],\n",
      "       [ 0.09674008,  0.98042289, -0.17150017],\n",
      "       [-0.69469352,  0.18990662,  0.69378411]]), 'azure_kinect_0-azure_kinect_1_T': array([-1668.51543707,   147.87110352,   802.06265815]), 'azure_kinect_1-kinect_v2_1_R': array([[ 0.43662653,  0.04648136,  0.89844129],\n",
      "       [-0.23860006,  0.96888414,  0.06582963],\n",
      "       [-0.86742567, -0.24311111,  0.43413097]]), 'azure_kinect_1-kinect_v2_1_T': array([-1937.00554847,  -244.77167949,  1052.98422726])}\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "temp_r , temp_t = RT_calculate(cams[cam_list[3]], cams[cam_list[4]])\n",
    "result[cam_list[3] + \"-\" + cam_list[4] + \"_R\"] = temp_r\n",
    "result[cam_list[3] + \"-\" + cam_list[4] + \"_T\"] = temp_t\n",
    "temp_r , temp_t = RT_calculate(cams[cam_list[2]], cams[cam_list[3]])\n",
    "result[cam_list[2] + \"-\" + cam_list[3] + \"_R\"] = temp_r\n",
    "result[cam_list[2] + \"-\" + cam_list[3] + \"_T\"] = temp_t\n",
    "temp_r , temp_t = RT_calculate(cams[cam_list[2]], cams[cam_list[1]])\n",
    "result[cam_list[2] + \"-\" + cam_list[1] + \"_R\"] = temp_r\n",
    "result[cam_list[2] + \"-\" + cam_list[1] + \"_T\"] = temp_t\n",
    "temp_r , temp_t = RT_calculate(cams[cam_list[1]], cams[cam_list[0]])\n",
    "result[cam_list[1] + \"-\" + cam_list[0] + \"_R\"] = temp_r\n",
    "result[cam_list[1] + \"-\" + cam_list[0] + \"_T\"] = temp_t\n",
    "print(result)\n",
    "with open('extrinsic.pkl','wb') as handle:\n",
    "    pickle.dump(result, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "cam_list = ['kinect_v2_1', 'azure_kinect_1','azure_kinect_0',  'azure_kinect_2', 'kinect_v2_2']\n",
    "result[cam_list[3] + \"-\" + cam_list[4] + \"_R\"] = np.array([[ 0.37361034,  0.18518875, -0.90891168],\n",
    "       [-0.17581992,  0.97624312,  0.12663618],\n",
    "       [ 0.91077037,  0.11249219,  0.39729439]])\n",
    "result[cam_list[3] + \"-\" + cam_list[4] + \"_T\"] = np.array([1960.23753113, -579.31185515, 1098.46230951])\n",
    "\n",
    "result[cam_list[2] + \"-\" + cam_list[3] + \"_R\"] = np.array([[ 0.57913545,  0.04026335, -0.81423645],\n",
    "       [-0.14330689,  0.98825489, -0.05306032],\n",
    "       [ 0.80253677,  0.14741481,  0.57810346]])\n",
    "result[cam_list[2] + \"-\" + cam_list[3] + \"_T\"] = np.array([1640.69515123,   12.86900027,  960.24096852])\n",
    "\n",
    "result[cam_list[2] + \"-\" + cam_list[1] + \"_R\"] = np.array([[ 0.66169192, -0.02274623,  0.74943073],\n",
    "       [ 0.19528112,  0.97027054, -0.14296978],\n",
    "       [-0.72389853,  0.24095162,  0.64646209]])\n",
    "result[cam_list[2] + \"-\" + cam_list[1] + \"_T\"] = np.array([-1747.72631593,    42.87419725,   933.11764652])\n",
    "\n",
    "result[cam_list[1] + \"-\" + cam_list[0] + \"_R\"] = np.array([[ 0.44199574,  0.02102015,  0.89677083],\n",
    "       [-0.14921203,  0.98752016,  0.05039556],\n",
    "       [-0.88451995, -0.15608362,  0.43961616]])\n",
    "result[cam_list[1] + \"-\" + cam_list[0] + \"_T\"] = np.array([-1723.2720887 ,  -411.90040134,  1212.71975883])\n",
    "#print(result)\n",
    "with open('extrinsic.pkl','wb') as handle:\n",
    "    pickle.dump(result, handle)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
